{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Video games sales prediction on region"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/Video_Games.csv')\n",
    "new_data = data.drop(['Name', 'Year_of_Release', 'Developer', 'Rating', 'Critic_Count', 'Critic_Score', 'User_Count', 'User_Score'], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 13375\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Platform       Genre                    Publisher  NA_Sales  EU_Sales  \\\n2151        PC      Action           Namco Bandai Games      0.25      0.56   \n3811        PS        Misc                   Aruze Corp      0.00      0.00   \n5944        PC  Simulation              Electronic Arts      0.02      0.24   \n15620     XOne      Action                      Ubisoft      0.00      0.02   \n4842        PS   Adventure  Sony Computer Entertainment      0.00      0.00   \n\n       JP_Sales  Other_Sales  Global_Sales  \n2151       0.00         0.14          0.96  \n3811       0.49         0.03          0.53  \n5944       0.00         0.04          0.29  \n15620      0.00         0.00          0.02  \n4842       0.37         0.03          0.40  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Platform</th>\n      <th>Genre</th>\n      <th>Publisher</th>\n      <th>NA_Sales</th>\n      <th>EU_Sales</th>\n      <th>JP_Sales</th>\n      <th>Other_Sales</th>\n      <th>Global_Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2151</th>\n      <td>PC</td>\n      <td>Action</td>\n      <td>Namco Bandai Games</td>\n      <td>0.25</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.14</td>\n      <td>0.96</td>\n    </tr>\n    <tr>\n      <th>3811</th>\n      <td>PS</td>\n      <td>Misc</td>\n      <td>Aruze Corp</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.49</td>\n      <td>0.03</td>\n      <td>0.53</td>\n    </tr>\n    <tr>\n      <th>5944</th>\n      <td>PC</td>\n      <td>Simulation</td>\n      <td>Electronic Arts</td>\n      <td>0.02</td>\n      <td>0.24</td>\n      <td>0.00</td>\n      <td>0.04</td>\n      <td>0.29</td>\n    </tr>\n    <tr>\n      <th>15620</th>\n      <td>XOne</td>\n      <td>Action</td>\n      <td>Ubisoft</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>4842</th>\n      <td>PS</td>\n      <td>Adventure</td>\n      <td>Sony Computer Entertainment</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.37</td>\n      <td>0.03</td>\n      <td>0.40</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into train and test and keep 20% for test\n",
    "train, test = train_test_split(new_data, test_size=0.2)\n",
    "print(f\"Train size: {len(train)}\")\n",
    "#show first 5 rows\n",
    "train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RN : correction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "268/268 [==============================] - 1s 951us/step - loss: 0.4906 - accuracy: 0.5562\n",
      "Epoch 2/25\n",
      "268/268 [==============================] - 0s 939us/step - loss: 0.4631 - accuracy: 0.6113\n",
      "Epoch 3/25\n",
      "268/268 [==============================] - 0s 915us/step - loss: 0.4552 - accuracy: 0.6183\n",
      "Epoch 4/25\n",
      "268/268 [==============================] - 0s 918us/step - loss: 0.4524 - accuracy: 0.6312\n",
      "Epoch 5/25\n",
      "268/268 [==============================] - 0s 917us/step - loss: 0.4504 - accuracy: 0.6366\n",
      "Epoch 6/25\n",
      "268/268 [==============================] - 0s 916us/step - loss: 0.4487 - accuracy: 0.6425\n",
      "Epoch 7/25\n",
      "268/268 [==============================] - 0s 926us/step - loss: 0.4477 - accuracy: 0.6523\n",
      "Epoch 8/25\n",
      "268/268 [==============================] - 0s 893us/step - loss: 0.4470 - accuracy: 0.6549\n",
      "Epoch 9/25\n",
      "268/268 [==============================] - 0s 982us/step - loss: 0.4472 - accuracy: 0.6646\n",
      "Epoch 10/25\n",
      "268/268 [==============================] - 0s 966us/step - loss: 0.4464 - accuracy: 0.6576\n",
      "Epoch 11/25\n",
      "268/268 [==============================] - 0s 865us/step - loss: 0.4463 - accuracy: 0.6657\n",
      "Epoch 12/25\n",
      "268/268 [==============================] - 0s 881us/step - loss: 0.4465 - accuracy: 0.6659\n",
      "Epoch 13/25\n",
      "268/268 [==============================] - 0s 926us/step - loss: 0.4459 - accuracy: 0.6635\n",
      "Epoch 14/25\n",
      "268/268 [==============================] - 0s 923us/step - loss: 0.4467 - accuracy: 0.6679\n",
      "Epoch 15/25\n",
      "268/268 [==============================] - 0s 906us/step - loss: 0.4470 - accuracy: 0.6680\n",
      "Epoch 16/25\n",
      "268/268 [==============================] - 0s 898us/step - loss: 0.4464 - accuracy: 0.6674\n",
      "Epoch 17/25\n",
      "268/268 [==============================] - 0s 950us/step - loss: 0.4469 - accuracy: 0.6717\n",
      "Epoch 18/25\n",
      "268/268 [==============================] - 0s 938us/step - loss: 0.4462 - accuracy: 0.6666\n",
      "Epoch 19/25\n",
      "268/268 [==============================] - 0s 927us/step - loss: 0.4473 - accuracy: 0.6744\n",
      "Epoch 20/25\n",
      "268/268 [==============================] - 0s 968us/step - loss: 0.4471 - accuracy: 0.6689\n",
      "Epoch 21/25\n",
      "268/268 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.6713\n",
      "Epoch 22/25\n",
      "268/268 [==============================] - 0s 959us/step - loss: 0.4474 - accuracy: 0.6743\n",
      "Epoch 23/25\n",
      "268/268 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.6661\n",
      "Epoch 24/25\n",
      "268/268 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.6680\n",
      "Epoch 25/25\n",
      "268/268 [==============================] - 0s 950us/step - loss: 0.4479 - accuracy: 0.6743\n",
      "105/105 [==============================] - 0s 869us/step - loss: 0.4196 - accuracy: 0.6579\n",
      "Test accuracy: 0.6578947305679321\n",
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "# Convertir les données d'entrée et de sortie en tenseurs NumPy\n",
    "X_train = np.array(train[['Genre', 'Platform']])\n",
    "y_train = np.array(train[['NA_Sales', 'EU_Sales', 'JP_Sales']])\n",
    "\n",
    "X_test = np.array(test[['Genre', 'Platform']])\n",
    "y_test = np.array(test[['NA_Sales', 'EU_Sales', 'JP_Sales']])\n",
    "\n",
    "# Encoder les données d'entrée en utilisant OneHotEncoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "# Construction du modèle\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=25, batch_size=50)\n",
    "\n",
    "# évaluation du modèle\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# prédiction sur de nouvelles données\n",
    "new_game = np.array([['Action', 'PS4']])\n",
    "new_game = encoder.transform(new_game) # Encoder la nouvelle donnée\n",
    "region_probs = model.predict(new_game)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def predict(game=\"Mario Kart 7\"):\n",
    "    # prédiction sur un jeu existant: game dans la base de données Video_Games\n",
    "    game_data = data[data['Name'] == game]\n",
    "    game_data = game_data.drop(['Name', 'Year_of_Release', 'Developer', 'Rating', 'Critic_Count', 'Critic_Score', 'User_Count', 'User_Score'], axis=1)\n",
    "\n",
    "    # compléter les données manquantes\n",
    "    new_game = np.array([game_data.iloc[0][['Genre', 'Platform']]])\n",
    "    new_game = encoder.transform(new_game) # Encoder la nouvelle donnée\n",
    "    region_probs = model.predict(new_game)\n",
    "\n",
    "    print(f\"Region probabilities for {game}: {region_probs}\")\n",
    "\n",
    "    # afficher les résultats\n",
    "    print(f\"North America: {region_probs[0][0]}\")\n",
    "    print(f\"Europe: {region_probs[0][1]}\")\n",
    "    print(f\"Japan: {region_probs[0][2]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Region probabilities for Mario Kart 7: [[0.42379454 0.40726084 0.16894463]]\n",
      "North America: 0.42379453778266907\n",
      "Europe: 0.40726083517074585\n",
      "Japan: 0.16894462704658508\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Region probabilities for Call of Duty: Black Ops II: [[0.5322652  0.42862785 0.03910702]]\n",
      "North America: 0.5322651863098145\n",
      "Europe: 0.4286278486251831\n",
      "Japan: 0.03910702094435692\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Region probabilities for Grand Theft Auto V: [[0.5086752  0.4333967  0.05792809]]\n",
      "North America: 0.508675217628479\n",
      "Europe: 0.43339669704437256\n",
      "Japan: 0.05792808532714844\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Region probabilities for Assassin's Creed Syndicate: [[0.4280832  0.5127239  0.05919292]]\n",
      "North America: 0.428083211183548\n",
      "Europe: 0.5127239227294922\n",
      "Japan: 0.059192921966314316\n"
     ]
    }
   ],
   "source": [
    "predict() # Mario Kart 7\n",
    "predict(\"Call of Duty: Black Ops II\") # Call of Duty: Black Ops II\n",
    "predict(\"Grand Theft Auto V\") # GTA5\n",
    "predict(\"Assassin's Creed Syndicate\") # Assassin's Creed IV: Black Flag"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FROM SCRATCH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "hidden_size = 32 # number of neurons in the hidden layer\n",
    "\n",
    "w1 = np.random.randn(input_size, hidden_size)\n",
    "w2 = np.random.randn(hidden_size, output_size)\n",
    "\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "b2 = np.zeros((1, output_size))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convertir les données d'entrée et de sortie en tenseurs NumPy\n",
    "X_train = np.array(train[['Genre', 'Platform']])\n",
    "y_train = np.array(train[['NA_Sales', 'EU_Sales', 'JP_Sales']])\n",
    "\n",
    "X_test = np.array(test[['Genre', 'Platform']])\n",
    "y_test = np.array(test[['NA_Sales', 'EU_Sales', 'JP_Sales']])\n",
    "\n",
    "# Encoder les données en utilisant OneHotEncoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_test = encoder.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# forward propagation\n",
    "def forward():\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
